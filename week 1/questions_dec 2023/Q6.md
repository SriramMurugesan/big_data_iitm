An enterprise software designer wants to leverage the best of cloud to minimize the number of administrative overheads associated with her big data pipeline while also getting on-demand scalability without sacrificing flexibility. What option should she choose to best serve these needs?

Options :

Build the data pipeline using Spark, data storage on HDFS, and deploy both onHadoop using IaaS

Build the data pipeline using Python run on Serverless where the data is storedon cloud storage

Build the data pipeline using Spark PaaS option on top of data stored on cloudstorage

Build the data pipeline using MapReduce, data storage on HDFS, and deployboth on Hadoop using IaaS

Answer : "Build the data pipeline using Spark PaaS option on top of data stored on cloud storage."